{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Jay Urbain, PhD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Review clustering and K-Means\n",
    "\n",
    "2 - Review clusting with scikit-learn and the iris dataset.\n",
    "\n",
    "3 - K-Mean clustering the adult dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering###\n",
    "\n",
    "You are given a data set where each observed example has a set of features, but has no labels. Labels are an essential for a supervised learning algorithm like *Logistic Regression*, which learns a model (hypothesis function) to predict labels given features. So what can we do to better understand the data?\n",
    "\n",
    "One of the most straightforward tasks we can perform on a dataset is to find groups of data which are similar to one another -- what we call clusters.\n",
    "\n",
    "*K-Means* is one of the most popular \"clustering\" algorithms. K-means stores *k* centroids that it uses to define clusters. A point (instance) is assigned to a particular cluster if it is *closer* to that cluster's centroid than any other cluster centroid.\n",
    "\n",
    "K-Means finds the best centroids by alternating between:\n",
    "\n",
    "1) assigning data points to clusters based on the current cluster centroids (cluster parameters)\n",
    "\n",
    "2) chosing centroids (points which are the center of a cluster) based on the current assignment of data points to clusters.\n",
    "\n",
    "<img src=\"kmeansViz.png\">\n",
    "\n",
    "*Figure 1: K-means algorithm. Training examples are shown as dots, and cluster centroids are shown as crosses. (a) Original dataset. (b) Random initial cluster centroids. (c-f) Illustration of running two iterations of k-means. In each iteration, we assign each training example to the closest cluster centroid (shown by \"painting\" the training examples the same color as the cluster centroid to which is assigned); then we move each cluster centroid to the mean of the points assigned to it. Images courtesy of Michael Jordan.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clustering with scikit-learn\n",
    "\n",
    "[http://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html#](http://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html#)\n",
    "\n",
    "The [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) used below consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray .\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets\n",
    "# plots within notebook versus launching a separate window\n",
    "%matplotlib inline \n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "print (X_iris[1:10,])\n",
    "print (type(X_iris))\n",
    "print (X_iris.shape)\n",
    "\n",
    "y_iris = iris.target\n",
    "print (type(y_iris))\n",
    "print (y_iris.shape)\n",
    "#print type(y_iris)\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X_iris) \n",
    "print('k_means labels:', k_means.labels_[1:10,])\n",
    "print('y_iris data:', y_iris[1:10,])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The plots below display what a *K-means* algorithm would yield using three clusters. It is then shown what the effect of a bad initialization is on the classification process: By setting *n_init* to only 1 (default is 10), the amount of times that the algorithm will be run with different centroid seeds is reduced. The next plot displays what using eight clusters would deliver, and finally the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "estimators = {'k_means_iris_3': KMeans(n_clusters=3),\n",
    "              'k_means_iris_8': KMeans(n_clusters=8),\n",
    "              'k_means_iris_bad_init': KMeans(n_clusters=3, n_init=1,\n",
    "                                              init='random')}\n",
    "\n",
    "fignum = 1\n",
    "for name, est in estimators.items():\n",
    "    fig = plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "    plt.cla()\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float))\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Petal width')\n",
    "    ax.set_ylabel('Sepal length')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    fignum = fignum + 1\n",
    "\n",
    "# Plot the ground truth\n",
    "fig = plt.figure(fignum, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "\n",
    "for name, label in [('Setosa', 0),\n",
    "                    ('Versicolour', 1),\n",
    "                    ('Virginica', 2)]:\n",
    "    ax.text3D(X[y == label, 3].mean(),\n",
    "              X[y == label, 0].mean() + 1.5,\n",
    "              X[y == label, 2].mean(), name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y)\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Petal width')\n",
    "ax.set_ylabel('Sepal length')\n",
    "ax.set_zlabel('Petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering the Adult Dataset\n",
    "\n",
    "The adult dataset is an example of a complex real world data set. In this dataset, the aim is to estimate if someone earns more than $50,000 per year. The dataset attributes describe a person, their environment, their background, and their life status.\n",
    "\n",
    "*Attribute Information*\n",
    "\n",
    "- \\>50K, <=50K. \n",
    "- age: continuous. \n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, - Without-pay, Never-worked. \n",
    "- fnlwgt: continuous. \n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "- education-num: continuous. \n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-- spouse-absent, Married-AF-spouse. \n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. \n",
    "- sex: Female, Male. \n",
    "- capital-gain: continuous. \n",
    "- capital-loss: continuous. \n",
    "- hours-per-week: continuous. \n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Download and examine the adult data set\n",
    "\n",
    "To download the dataset, navigate to [http://archive.ics.uci.edu/ml/datasets/Adult](http://archive.ics.uci.edu/ml/datasets/Adult), click on the *Data Folder* link, \n",
    "and download the *adult.data* and *adult.names* files into a *data* subdirectory to your IPython notebook. You can also read a description of the dataset.\n",
    "\n",
    "The adult dataset can be used for classifiction, but we are going to see what we can discover about relationships in the data using clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "adult_filename= \"data/adult.data\"\n",
    "\n",
    "adult = pd.read_csv(adult_filename, header=None,\n",
    "    names=[\"Age\", \"Work-Class\",\"fnlwgt\", \n",
    "    \"Education\", \"Education-Num\",\n",
    "    \"Martial-Status\", \"Occupation\",\n",
    "    \"Relationship\", \"Race\", \"Sex\",\n",
    "    \"Capital-gain\", \"Captial-loss\",\n",
    "    \"Hours-per-week\", \"Natie-Country\",\n",
    "    \"Earnings-Raw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data \n",
    "# Note: there are many attributes, so you may need to scroll right\n",
    "\n",
    "adult.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files can contain extra blank lines at the end of the file. By default, *pandas* will interpret the penultimate new line to be an empty (but valid) row. To remove this, remvove any row with invalid numbers. The *inplace* parameter just makes the change in the give Dataframe, rather than create a new Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (adult.shape)\n",
    "adult.dropna(how='all', inplace=True)\n",
    "print (adult.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)  Examining the attributes\n",
    "\n",
    "Pandas dataframes provide useful functions for describing a dataset. \n",
    "\n",
    "You can access each column as shown below. There are several functions you can run on each column to better understand the type and distribution of each attribute. Some functions may not make sense, e.g., mean of Marital-Status.\n",
    "\n",
    "[http://pandas.pydata.org/pandas-docs/version/0.17.0/api.html](http://pandas.pydata.org/pandas-docs/version/0.17.0/api.html)\n",
    "\n",
    "a) Add additional notebook cells below to examine *each* column in the dataset. \n",
    "\n",
    "b) For each column, identify the data type as numeric, ordinal, or categorical. \n",
    "\n",
    "I've provided some examples. In each case, you want to examine some of the rows in the dataset. You can use the dataframe head() function. For numeric attributes consider using the pandas dataframe describe() and matplotlib histogram plot functions. For categorical and ordinal attributes you can generate a crosstab table and a matplotlib barplot. *Note: You can use crosstab for comparing different attributes that share the same categories.* To compare numberic attributes, you can use a scatter plot. Many options here. Experiment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult['Age'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique categorical values\n",
    "adult[\"Work-Class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross tab\n",
    "result = adult[['Work-Class']].apply(pd.value_counts).fillna(0).T\n",
    "result.index=['Work-Class']\n",
    "result.columns=[' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
    "       ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked']\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# cross tabulated result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# horizontal bar plot\n",
    "plt=result.plot.barh(title=\"Work Class\")\n",
    "plt.set_xlabel(\"Number of workers\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"Hours-per-week\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"fnlwgt\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Feature selection and normalization\n",
    "\n",
    "From your analysis in (1) above, select at least 6 distinct attributes in addition to income for clustering. By distinct, I’m refering to non-redundant, i.e., non-correlated, feature attributes. For example, don’t select both forms of education. \n",
    "\n",
    "Select features you think may have a strong (positive or negative) association with higher income, and select features of multile types, e.g., continuous, discrete, ordinal, and categorical. You may select more, and you may want to change your feature selection as you experiment.\n",
    "\n",
    "Feel free to use additional tools we learned as part of our data analysis work.\n",
    "\n",
    "You also may want to not select columns with many missing values.\n",
    "\n",
    "Enter your attribute selections in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature normalization**\n",
    "\n",
    "For each of your selected features, identify a strategy to normalize your data between 0 and 1.\n",
    "\n",
    "- Numerical attributes, e.g., income, are normalized to values between 0 and 1 using min-max normalization. \n",
    "- Ordinal attributes, i.e., education, are normalized to a range of 0 to 1. \n",
    "- Boolean attributes are set to either 0 or 1.\n",
    "- Categorical attributes are assigned an integer enumerated type, e.g., 1, 2, 3, ... and return 1 if there is a match, 0 otherwise.\n",
    "\n",
    "Define your strategy and normalize each of your features in the cell(s) below. This is arguably the most important step in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Missing values **\n",
    "\n",
    "Examine the dataset, and your selected features for missing values. You will need to come up with a strategy for dealing with missing values for each of your selected attributes. \n",
    "\n",
    "Strategies:\n",
    "\n",
    "- Replace mssing values with the most likely value, e.g., mode for categorical or boolean, mean for continuous, etc. This can be risky, since you distort the relationships in the data.\n",
    "- Encode missing values that will work within a *distance* function. Sometimes, the fact that the feature *is* missing has meaning.\n",
    "- Just delete the row containing the missing value. As long as you do not throw away too much data, this can be the best strategy.\n",
    "\n",
    "Define your missing value strategy in the cell(s) below and correct missing values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Creating a cluster dataset\n",
    "\n",
    "Using your selected attributes and the income attribute, create a new *clustering* dataframe where each attriubte is normalized and where you've dealth with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Validate your clustering dataframe**\n",
    "\n",
    "This may be the most important step. Examine the records in your database, and run the appropriate statistical methods on each of your selected attribute columns to make sure everything is sane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) K-Means Clustering\n",
    "\n",
    "1 - Use scikit-learn and implement the function *get_kmeans_score(data,K)*\"\n",
    "\n",
    "2 - Run your solution for 1 to 10 values of K. \n",
    "\n",
    "3 - Save SSE values for each trial in a list. To obtain a score related to the model fit:   \n",
    "    `score = np.abs(model.score(data))`\n",
    "\n",
    "4 - Plot your results in a scree plot similar to the following:\n",
    "\n",
    "<img src=\"screeplot.png\">\n",
    "\n",
    "5 - Identify your optimal value for K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_score(data, K):\n",
    "    '''\n",
    "    returns the kmeans score regarding SSE for points to centers\n",
    "    INPUT:\n",
    "        data - the dataset you want to fit kmeans to\n",
    "        K - the number of centroids you want (the k value)\n",
    "    OUTPUT:\n",
    "        score - the SSE score for the kmeans model fit to the data\n",
    "    '''\n",
    "    \n",
    "    # your work here\n",
    "    score 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Clustering evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat step (5) above for k=2,3,4, and 5.\n",
    "\n",
    "Tabulate your results for k=2,3,4,5, and 6 (your first trial).\n",
    "\n",
    "Qualitatively which value of k provided the best clustering results?\n",
    "\n",
    "What attributes are the most effective for generating clusters for income (without using the income attribute!)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Clustering using other methods\n",
    "\n",
    "Apply hierarchical aglomerative clustering to the same data set. Experiment with 2 or 3 different linkages. For each case display the Cophenetic Correlation Coefficient, and generate a dendogram. See the [SciPy Hierarchical Clustering and Dendrograms](../../notebooks/SciPy%20Hierarchical%20Clustering%20and%20Dendrograms.ipynb) for tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgmpy35x1",
   "language": "python",
   "name": "pgmpy35x1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
